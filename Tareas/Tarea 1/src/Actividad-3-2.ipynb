{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oscar Esaú Peralta Rosales\n",
    "## Tarea 1: Fundamentos de Minería de Texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import CategorizedPlaintextCorpusReader\n",
    "from nltk.tokenize import WordPunctTokenizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad 3: Detección de Agresividad con Análisis de Sentimiento Básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mex_corpus = CategorizedPlaintextCorpusReader('./data/corpus/', r'.*\\.txt', cat_pattern=r'(\\w+)/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = TweetTokenizer() \n",
    "stopw = stopwords.words('spanish') + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [ \n",
    "            [token for token in tk.tokenize(tweet) if token not in stopw and len(token) > 2]\n",
    "            for tweet in mex_corpus.raw('mex_train.txt').split('\\n') if tweet\n",
    "          ]\n",
    "y_train = [int(label) for label in mex_corpus.raw('mex_train_labels.txt').split('\\n') if label ]\n",
    "x_val = [ \n",
    "            [token for token in tk.tokenize(tweet) if token not in stopw and len(token) > 2]\n",
    "            for tweet in mex_corpus.raw('mex_val.txt').split('\\n') if tweet\n",
    "        ]\n",
    "y_val = [int(label) for label in mex_corpus.raw('mex_val_labels.txt').split('\\n') if label ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Utilice el recurso léxico llamado \"Spanish Emotion Lexicon (SEL)\" del Dr. Grigori Sidorov, profesor del Centro de Investigación en Computación (CIC) del Instituto Politecnico Nacional (http://www.cic.ipn.mx/∼sidorov/), para enmascarar cada palabra con su emoción, y después construir la Bolsa de Emociones con algún pesado (e.g., binario, tf, tfidf). Considere alguna estrategia para incorporar el \"valor\" del \"Probability Factor of Affective use\" en su representación vectorial del documento. Evalúa varias representaciones, y ponga una tabla comparativa a modo de resumen (e.g., binario, frecuencia, tfidf, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data/SEL/SEL.csv'\n",
    "\n",
    "with open(file_name) as fs:\n",
    "    sel = [line.split(',') for line in fs if line]\n",
    "\n",
    "sel_map = { unidecode.unidecode(item[1]).lower(): (item[7], float(item[6])) for item in sel[1:]}\n",
    "sel_vocab = dict(zip(set([item[1][0] for item in sel_map.items()]), range(6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construcción de la bolsa de emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_emotions_bow(docs, sel_map, sel_vocab):\n",
    "    \"\"\" Build a emotions bag \"\"\"\n",
    "    bows = np.zeros((len(docs), len(sel_vocab)), dtype=float)\n",
    "    \n",
    "    for index, doc in enumerate(tqdm(docs)):\n",
    "        for _word in doc:\n",
    "            word = unidecode.unidecode(_word)\n",
    "            if not word in sel_map:\n",
    "                continue\n",
    "            # Increase by pfa\n",
    "            bows[index][sel_vocab[sel_map[word][0]]] += sel_map[word][1]\n",
    "            \n",
    "    return bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5544/5544 [00:00<00:00, 55725.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       ...,\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.966]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = build_emotions_bow(x_train, sel_map, sel_vocab)\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x_train, y_train, x_val, y_val, kbest=None):\n",
    "    \"\"\" Clasificación con SVM, feature selection with chi2 \"\"\"\n",
    "    parameters = {'C': [.05, .12, .25, .5, 1, 2, 4]}\n",
    "    \n",
    "    if kbest:\n",
    "        selectk = SelectKBest(chi2, k=kbest)\n",
    "        selectk.fit(x_train, y_train)\n",
    "        x_train = selectk.transform(x_train)\n",
    "        x_val = selectk.transform(x_val)\n",
    "    \n",
    "    svr = svm.LinearSVC(class_weight='balanced')\n",
    "    grid = GridSearchCV(estimator=svr, param_grid=parameters, n_jobs=8, scoring=\"f1_macro\", cv=5)\n",
    "    \n",
    "    grid.fit(x_train, y_train) \n",
    "\n",
    "    y_pred = grid.predict(x_val)\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_val, y_pred, average='macro', pos_label=None)\n",
    "    a = accuracy_score(y_val, y_pred)\n",
    "    print(confusion_matrix(y_val, y_pred) )\n",
    "    print(metrics.classification_report(y_val, y_pred))\n",
    "    return p, r , f, a\n",
    "\n",
    "metrics_hist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bolsa de emociones binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_binary_bow(emotions_bow):\n",
    "    \"\"\" Build a emotions binary bow \"\"\"\n",
    "    bow = emotions_bow.copy()\n",
    "    bow[emotions_bow > 0] = 1\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5544/5544 [00:00<00:00, 51841.10it/s]\n",
      "100%|██████████| 616/616 [00:00<00:00, 89574.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[355  42]\n",
      " [177  42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76       397\n",
      "           1       0.50      0.19      0.28       219\n",
      "\n",
      "    accuracy                           0.64       616\n",
      "   macro avg       0.58      0.54      0.52       616\n",
      "weighted avg       0.61      0.64      0.59       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nx_train = build_binary_bow(build_emotions_bow(x_train, sel_map, sel_vocab))\n",
    "nx_val = build_binary_bow(build_emotions_bow(x_val, sel_map, sel_vocab))\n",
    "metrics_hist.append((\"Bolsa de emociones binaria\", \n",
    "                     *classify(nx_train, y_train, nx_val, y_val, kbest=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bolsa de emociones frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frecs_bow(emotions_bow, normalize=False):\n",
    "    \"\"\" Build a emotions frequencies bow \"\"\"\n",
    "    # The bow already has the frequencies\n",
    "    bow = emotions_bow.copy()\n",
    "    if normalize:\n",
    "        for row in bow:\n",
    "            row /= np.linalg.norm(row) or 1.0\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5544/5544 [00:00<00:00, 57548.50it/s]\n",
      "100%|██████████| 616/616 [00:00<00:00, 94003.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[352  45]\n",
      " [176  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76       397\n",
      "           1       0.49      0.20      0.28       219\n",
      "\n",
      "    accuracy                           0.64       616\n",
      "   macro avg       0.58      0.54      0.52       616\n",
      "weighted avg       0.60      0.64      0.59       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nx_train = build_frecs_bow(build_emotions_bow(x_train, sel_map, sel_vocab))\n",
    "nx_val = build_frecs_bow(build_emotions_bow(x_val, sel_map, sel_vocab))\n",
    "metrics_hist.append((\"Bolsa de emociones frecuencias\", \n",
    "                     *classify(nx_train, y_train, nx_val, y_val, kbest=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bolsa de emociones de frecuencias normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5544/5544 [00:00<00:00, 91230.25it/s]\n",
      "100%|██████████| 616/616 [00:00<00:00, 87835.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 78 319]\n",
      " [ 18 201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.20      0.32       397\n",
      "           1       0.39      0.92      0.54       219\n",
      "\n",
      "    accuracy                           0.45       616\n",
      "   macro avg       0.60      0.56      0.43       616\n",
      "weighted avg       0.66      0.45      0.40       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nx_train = build_frecs_bow(build_emotions_bow(x_train, sel_map, sel_vocab), normalize=True)\n",
    "nx_val = build_frecs_bow(build_emotions_bow(x_val, sel_map, sel_vocab), normalize=True)\n",
    "metrics_hist.append((\"Bolsa de emociones frecuencias norm\", \n",
    "                     *classify(nx_train, y_train, nx_val, y_val, kbest=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bolsa de emociones tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tfidf_bow(emotions_bows, normalize=False):\n",
    "    \"\"\" Build a emotions tfidf bow \"\"\"\n",
    "    bows = emotions_bows.copy()\n",
    "    # Compute count of terms by document\n",
    "    ndocs_terms = np.sum(emotions_bows > 0, axis=0)\n",
    "    zeros = np.where(ndocs_terms == 0)[0]\n",
    "    ndocs_terms[zeros] = 1\n",
    "    for bow in bows:\n",
    "        # compute tf\n",
    "        bow /= np.sum(bow > 0) or 1\n",
    "        bow *= np.log(emotions_bows.shape[0] / ndocs_terms)\n",
    "        bow[zeros] = 0.0\n",
    "        if normalize:\n",
    "            bow /= np.linalg.norm(bow) or 1.0\n",
    "    return bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5544/5544 [00:00<00:00, 58897.99it/s]\n",
      "100%|██████████| 616/616 [00:00<00:00, 78658.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 77 320]\n",
      " [ 19 200]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.19      0.31       397\n",
      "           1       0.38      0.91      0.54       219\n",
      "\n",
      "    accuracy                           0.45       616\n",
      "   macro avg       0.59      0.55      0.43       616\n",
      "weighted avg       0.65      0.45      0.39       616\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esau/.pyenv/versions/3.7.6/envs/stuffs/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "nx_train = build_tfidf_bow(build_emotions_bow(x_train, sel_map, sel_vocab))\n",
    "nx_val = build_tfidf_bow(build_emotions_bow(x_val, sel_map, sel_vocab))\n",
    "metrics_hist.append((\"Bolsa de emociones tfidf\", \n",
    "                     *classify(nx_train, y_train, nx_val, y_val, kbest=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bolsa de emociones tfidf normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5544/5544 [00:00<00:00, 93223.94it/s]\n",
      "100%|██████████| 616/616 [00:00<00:00, 86203.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 78 319]\n",
      " [ 18 201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.20      0.32       397\n",
      "           1       0.39      0.92      0.54       219\n",
      "\n",
      "    accuracy                           0.45       616\n",
      "   macro avg       0.60      0.56      0.43       616\n",
      "weighted avg       0.66      0.45      0.40       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nx_train = build_tfidf_bow(build_emotions_bow(x_train, sel_map, sel_vocab), normalize=True)\n",
    "nx_val = build_tfidf_bow(build_emotions_bow(x_val, sel_map, sel_vocab), normalize=True)\n",
    "metrics_hist.append((\"Bolsa de emociones tfidf norm\", \n",
    "                     *classify(nx_train, y_train, nx_val, y_val, kbest=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tabla comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Fscore</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bolsa de emociones binaria</td>\n",
       "      <td>0.583647</td>\n",
       "      <td>0.542994</td>\n",
       "      <td>0.520745</td>\n",
       "      <td>0.644481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsa de emociones frecuencias</td>\n",
       "      <td>0.577652</td>\n",
       "      <td>0.541498</td>\n",
       "      <td>0.520606</td>\n",
       "      <td>0.641234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bolsa de emociones frecuencias norm</td>\n",
       "      <td>0.599519</td>\n",
       "      <td>0.557141</td>\n",
       "      <td>0.430204</td>\n",
       "      <td>0.452922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bolsa de emociones tfidf</td>\n",
       "      <td>0.593349</td>\n",
       "      <td>0.553598</td>\n",
       "      <td>0.426823</td>\n",
       "      <td>0.449675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bolsa de emociones tfidf norm</td>\n",
       "      <td>0.599519</td>\n",
       "      <td>0.557141</td>\n",
       "      <td>0.430204</td>\n",
       "      <td>0.452922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Embedding  Precision    Recall    Fscore  \\\n",
       "0           Bolsa de emociones binaria   0.583647  0.542994  0.520745   \n",
       "1       Bolsa de emociones frecuencias   0.577652  0.541498  0.520606   \n",
       "2  Bolsa de emociones frecuencias norm   0.599519  0.557141  0.430204   \n",
       "3             Bolsa de emociones tfidf   0.593349  0.553598  0.426823   \n",
       "4        Bolsa de emociones tfidf norm   0.599519  0.557141  0.430204   \n",
       "\n",
       "   Accuracy  \n",
       "0  0.644481  \n",
       "1  0.641234  \n",
       "2  0.452922  \n",
       "3  0.449675  \n",
       "4  0.452922  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(data=metrics_hist, columns = ['Embedding', 'Precision', 'Recall', 'Fscore', 'Accuracy'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En un comentario aparte, discuta sobre la estrategía que utilizó para incorporar el \"Probability Factor of Affective use\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para agregar el PFA a la bolsa de emociones se optó por no contabilizar cada match de una palabra con una emoción como 1 (es decir, realizar acumulaciones de uno en uno) sino que contar la influecia de cada match a una emoción mediante su PFA, es decir se acumulan los PFA de las palabras por cada match con una emoción. Así tratar de ponderar la influencia de cada emoción por tweet a través del PFA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
